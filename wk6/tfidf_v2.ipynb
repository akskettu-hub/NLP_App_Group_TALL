{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f88af142-18f7-4709-ae5c-a1a5727a9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "92ed5d1c-6bbf-491b-ba46-ce5ae3c63251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please Enter your query, type 'quit' to exit:  yhtiöjärjestykseen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 1 matches:\n",
      "\n",
      "Matching doc #1:\n",
      "Title: KKO:2025:13\n",
      "Link: https://www.finlex.fi/fi/oikeus/kko/kko/2025/20250013\n",
      "Diaarinumero: S2023/375\n",
      "Antopäivä: 23.1.2025\n",
      "Description:\n",
      "Osakeyhtiön yhtiökokous päätti ottaa yhtiöjärjestykseen määräyksen siitä, että osakkeenomistaja, jonka osuus yhtiön osakkeiden tuottamasta äänimäärästä saavutti tai ylitti 30 prosenttia tai 50 prosenttia, oli velvollinen lunastamaan muiden osakkeenomistajien vaatimuksesta näiden osakkeet. Lunastushinta oli yhtiöjärjestyksessä tarkemmin määrätyllä tavalla vahvis...\n",
      "(score: 0.1328)\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please Enter your query, type 'quit' to exit:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exit\n"
     ]
    }
   ],
   "source": [
    "def load_documents(file_path):\n",
    "    documents = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "        \n",
    "## updated funtion per Friday's discussion\n",
    "    for year, cases in data.items():\n",
    "        for case_info in cases.values():  \n",
    "            text_content = []\n",
    "            \n",
    "            if \"Title\" in case_info:\n",
    "                text_content.append(f\"Title: {case_info['Title']}\")  \n",
    "            \n",
    "            if \"Metadata\" in case_info:\n",
    "                metadata = case_info[\"Metadata\"]\n",
    "                if \"Link\" in metadata:\n",
    "                    text_content.append(f\"Link: {metadata['Link']}\")\n",
    "                if \"Diaarinumero:\" in metadata:\n",
    "                    text_content.append(f\"Diaarinumero: {metadata['Diaarinumero:']}\")\n",
    "                if \"Antopäivä:\" in metadata:\n",
    "                    text_content.append(f\"Antopäivä: {metadata['Antopäivä:']}\")\n",
    "            \n",
    "            if \"Description\" in case_info:\n",
    "                text_content.append(\"Description:\")\n",
    "                text_content.extend(case_info[\"Description\"])\n",
    "            \n",
    "            ### Suppose we want what's in the \"content\" entries:\n",
    "            '''\n",
    "            for section in [\"Asian käsittely alemmissa oikeuksissa\", \"Muutoksenhaku Korkeimmassa oikeudessa\", \"Korkeimman oikeuden ratkaisu\"]:\n",
    "                if section in case_info and \"Contents\" in case_info[section]:\n",
    "                    text_content.append(f\"\\n{section}:\")\n",
    "                    text_content.extend(case_info[section][\"Contents\"])\n",
    "            '''\n",
    "            \n",
    "            documents.append(\"\\n\".join(text_content))\n",
    "\n",
    "    return documents\n",
    "# Document setup using TfidfVectorizer\n",
    "def tf_document_setup(documents):\n",
    "    tfv = TfidfVectorizer(lowercase=True, sublinear_tf=True, use_idf=True, norm=\"l2\") \n",
    "    tf_matrix = tfv.fit_transform(documents).T.todense() \n",
    "    return tf_matrix, tfv\n",
    "\n",
    "def user_query():\n",
    "    print()\n",
    "    user_input = input(\"Please Enter your query, type 'quit' to exit: \")\n",
    "    print()\n",
    "    return user_input\n",
    "\n",
    "\n",
    "def input_checker(user_input):\n",
    "    if user_input == \"quit\" or user_input == \"\":\n",
    "           print(\"Exit\")\n",
    "           return False\n",
    "    return True\n",
    "\n",
    "# Compute cosine similarity scores\n",
    "def retrieve_matches(query, tf_matrix, tfv):\n",
    "    query_tf = tfv.transform([query]).todense()  # Convert query to tf-idf vector\n",
    "    scores = np.dot(query_tf, tf_matrix)  # Compute cosine similarity score\n",
    "    return scores\n",
    "\n",
    "def tf_print_retrieved(scores, documents):\n",
    "    if np.all(scores == 0):  \n",
    "        print(\"No matching document\")\n",
    "    else:\n",
    "        ranked_scores_and_doc_ids = sorted([(score, i) for i, score in enumerate(np.array(scores)[0]) if score > 0], reverse=True) # Rank the documents by similarity score\n",
    "        \n",
    "        print(f\"Found {len(ranked_scores_and_doc_ids)} matches:\")\n",
    "        \n",
    "        print_limit = 500  # Change the number here to determine the output length\n",
    "        for rank, (score, i) in enumerate(ranked_scores_and_doc_ids):\n",
    "            matched_doc = documents[i]\n",
    "            limit_doc = matched_doc[:print_limit]  \n",
    "            \n",
    "            limit_doc += \"...\"  \n",
    "            \n",
    "            print(f\"\\nMatching doc #{rank + 1}:\")\n",
    "            print(limit_doc) \n",
    "            print(f\"(score: {score:.4f})\")  \n",
    "\n",
    "\n",
    "            \n",
    "def main():\n",
    "    while True:\n",
    "        user_input = user_query()\n",
    "        if not input_checker(user_input):\n",
    "            break\n",
    "        scores = retrieve_matches(user_input, tf_matrix, tfv)\n",
    "        tf_print_retrieved(scores, documents)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'en_sample_database.json'\n",
    "    documents = load_documents(file_path)\n",
    "    tf_matrix, tfv = tf_document_setup(documents)  \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97aad62-c905-483a-865d-1eb391b6f92d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
